{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/mh1022/dl_cw_pyenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from data.preprocess import DataProcessor\n",
    "import os\n",
    "from data.custom_dataset import CustomDataset\n",
    "from data.utils import get_dataset, get_tokenizer, get_dataloader\n",
    "from model.model import Model\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import ast\n",
    "import os\n",
    "import itertools\n",
    "import torch.utils.checkpoint\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from training.trainer import Trainer\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/mh1022/temporal-modelling-icd/data/preprocess.py:16: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.notes_df = pd.read_csv(os.path.join(dataset_path, \"NOTEEVENTS.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nursing/other': 0, 'Radiology': 1, 'Nursing': 2, 'Physician ': 3, 'ECG': 4, 'Discharge summary': 5, 'Respiratory ': 6, 'Echo': 7, 'Nutrition': 8, 'General': 9, 'Rehab Services': 10, 'Social Work': 11, 'Case Management ': 12, 'Consult': 13, 'Pharmacy': 14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "# parser = argparse.ArgumentParser(description=\"Train model\",\n",
    "#                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "# parser.add_argument(\"-n\", \"--num_chunks\", type=int, help=\"number of chunks\")\n",
    "# parser.add_argument(\"-r\", \"--run_name\", type=str, help=\"run name\")\n",
    "# parser.add_argument(\"-m\", \"--max_epochs\", type=int, help=\"number of max epochs\")\n",
    "# parser.add_argument(\"-l\", \"--num_heads_labattn\", type=int, help=\"number of heads for lab attention\")\n",
    "# parser.add_argument(\"-p\", \"--patience_threshold\", type=int, help=\"patience threshold\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# args_config = vars(args)\n",
    "\n",
    "# # device\n",
    "USE_GPU = True\n",
    "dtype = torch.float32\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "cpu = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "### for debugging use cpu\n",
    "#device = cpu\n",
    "\n",
    "config = {\n",
    "#    \"run_name\": \"Run_test_TLWAN\"\n",
    "    \"run_name\": \"test\"\n",
    "    ,\"project_path\": '/vol/bitbucket/mh1022/temporal-modelling-icd'\n",
    "    ,\"base_checkpoint\": os.path.join(\"\", \"RoBERTa-base-PM-M3-Voc-hf\")\n",
    "    ,\"num_attention_heads\": 1\n",
    "    ,\"num_layers\": 1\n",
    "    ,\"lr\": 5e-5\n",
    "    ,\"max_chunks\": 16\n",
    "    ,\"grad_accumulation\": 16\n",
    "    ,\"use_positional_embeddings\": True\n",
    "    ,\"use_reverse_positional_embeddings\": True\n",
    "    ,\"priority_mode\": \"None\"\n",
    "    ,\"priority_idxs\": [1]\n",
    "    ,\"use_document_embeddings\": True\n",
    "    ,\"use_reverse_document_embeddings\": True\n",
    "    ,\"use_category_embeddings\": True\n",
    "    ,\"num_labels\": 50\n",
    "    ,\"use_all_tokens\": True\n",
    "    ,\"num_heads_labattn\": 1\n",
    "    ,\"final_aggregation\": \"cls\"\n",
    "    ,\"only_discharge_summary\": False\n",
    "    ,\"patience_threshold\": 3\n",
    "    ,\"max_epochs\": 20\n",
    "    ,\"save_model\": False\n",
    "    ,\"load_from_checkpoint\": False\n",
    "    ,\"checkpoint_name\": \"Run_all_notes_last_second_transf\"\n",
    "    ,\"evaluate_temporal\": False\n",
    "    ,\"use_multihead_attention\": False\n",
    "    ,\"debug\": False\n",
    "}\n",
    "with open(os.path.join(\"\", f\"results/config_{config['run_name']}.json\"), \"w\") as f:\n",
    "    json.dump(config, f)\n",
    "\n",
    "# process and aggregate raw data\n",
    "dp = DataProcessor(dataset_path=\"dataset\", config=config)\n",
    "notes_agg_df = dp.aggregate_data()\n",
    "\n",
    "# get tokenizer\n",
    "tokenizer = get_tokenizer(config[\"base_checkpoint\"])\n",
    "\n",
    "# Get training / validation / test\n",
    "dataset_config = {\n",
    "    \"max_chunks\" : config[\"max_chunks\"],\n",
    "    \"priority_mode\" : config[\"priority_mode\"],\n",
    "    \"priority_idxs\" : config[\"priority_idxs\"]\n",
    "}\n",
    "training_set = get_dataset(notes_agg_df, \"TRAIN\", tokenizer = tokenizer, **dataset_config)\n",
    "training_generator = get_dataloader(training_set)\n",
    "\n",
    "validation_set =  get_dataset(notes_agg_df, \"VALIDATION\", tokenizer = tokenizer, **dataset_config)\n",
    "validation_generator = get_dataloader(validation_set)\n",
    "\n",
    "test_set = get_dataset(notes_agg_df, \"TEST\", tokenizer = tokenizer, **dataset_config)\n",
    "test_generator = get_dataloader(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "import tqdm as tqdm\n",
    "import torch.optim as optim\n",
    "import ast\n",
    "import os\n",
    "import itertools\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.checkpoint\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from evaluation.metrics import MyMetrics\n",
    "from evaluation.evaluate import evaluate\n",
    "from data.custom_dataset import OneSampleDataset\n",
    "import ipdb\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModel,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, sample in enumerate(tqdm(training_generator)):\n",
    "    # First pass through the model: obtain largest gradients\n",
    "    one_sample_dataset = OneSampleDataset(sample)\n",
    "    one_sample_dataloader = DataLoader(one_sample_dataset, batch_size=config[\"max_chunks\"], shuffle=False)\n",
    "    for j, data in enumerate(tqdm(one_sample_dataloader)):\n",
    "        labels = data[\"label\"][0][: 50]\n",
    "        input_ids = data[\"input_ids\"][0]\n",
    "        attention_mask = data[\"attention_mask\"][0]\n",
    "        seq_ids = data[\"seq_ids\"][0]\n",
    "        category_ids = data[\"category_ids\"][0]\n",
    "        # note_end_chunk_ids = data[\"note_end_chunk_ids\"]\n",
    "        cutoffs = data[\"cutoffs\"]\n",
    "        print(input_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 38, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, sample in enumerate(tqdm(training_generator)):\n",
    "    # First pass through the model: obtain largest gradients\n",
    "    one_sample_dataset = OneSampleDataset(sample)\n",
    "    one_sample_dataloader = DataLoader(one_sample_dataset, batch_size=self.config[\"max_chunks\"], shuffle=False)\n",
    "    for j, data in enumerate(tqdm(one_sample_dataloader)):\n",
    "        labels = data[\"label\"][0][: self.model.num_labels]\n",
    "        input_ids = data[\"input_ids\"][0]\n",
    "        attention_mask = data[\"attention_mask\"][0]\n",
    "        seq_ids = data[\"seq_ids\"][0]\n",
    "        category_ids = data[\"category_ids\"][0]\n",
    "        # note_end_chunk_ids = data[\"note_end_chunk_ids\"]\n",
    "        cutoffs = data[\"cutoffs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    54,  5478,  ...,     1,     1,     1],\n",
       "        [    0,    68, 47179,  ...,     1,     1,     1],\n",
       "        [    0,  9807,    56,  ...,     1,     1,     1],\n",
       "        [    0,  3009,  2137,  ...,    17, 16122,     2],\n",
       "        [    0,  7714, 22631,  ...,     1,     1,     1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = training_set[0]\n",
    "one_sample_dataset = OneSampleDataset(sample)\n",
    "one_sample_data_loader =DataLoader(one_sample_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 512])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_sample_dataset[0][\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(one_sample_data_loader))[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1351.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for j, data in enumerate(tqdm(one_sample_data_loader)):\n",
    "    labels = data[\"label\"][0][: 50]\n",
    "    input_ids = data[\"input_ids\"][0]\n",
    "    attention_mask = data[\"attention_mask\"][0]\n",
    "    seq_ids = data[\"seq_ids\"][0]\n",
    "    category_ids = data[\"category_ids\"][0]\n",
    "    # note_end_chunk_ids = data[\"note_end_chunk_ids\"]\n",
    "    cutoffs = data[\"cutoffs\"]\n",
    "    print(input_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_encodings = torch.rand((4, 512, 768))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_encodings.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = token_encodings.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_encodings.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"seq_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"input_ids\"][0,:].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_cw_pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
